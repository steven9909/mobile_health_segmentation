{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFS(mask):\n",
    "    visited = np.zeros_like(mask, dtype=np.int32)\n",
    "\n",
    "    max_size = 0\n",
    "\n",
    "    for iy, ix in np.ndindex(mask.shape):\n",
    "        if mask[iy, ix] == 0 or (visited[iy, ix] == -1 and mask[iy, ix] == 255):\n",
    "            continue\n",
    "        else:\n",
    "            queue = [(iy, ix)]\n",
    "            size = 0\n",
    "            while len(queue) > 0:\n",
    "                y, x = queue.pop()\n",
    "                visited[y, x] = -1\n",
    "                size += 1\n",
    "                for dy, dx in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
    "                    if 0 <= y + dy < mask.shape[0] and 0 <= x + dx < mask.shape[1]:\n",
    "                        if mask[y + dy, x + dx] == 255 and visited[y + dy, x + dx] == 0:\n",
    "                            queue.append((y + dy, x + dx))\n",
    "\n",
    "            visited[iy, ix] = size\n",
    "            max_size = max(max_size, size)\n",
    "\n",
    "    for iy, ix in np.ndindex(visited.shape):\n",
    "        if 0 < visited[iy, ix] < max_size and mask[iy, ix] == 255:\n",
    "            queue = [(iy, ix)]\n",
    "            while len(queue) > 0:\n",
    "                y, x = queue.pop()\n",
    "                mask[y, x] = 0\n",
    "                for dy, dx in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
    "                    if 0 <= y + dy < mask.shape[0] and 0 <= x + dx < mask.shape[1]:\n",
    "                        if mask[y + dy, x + dx] == 255:\n",
    "                            queue.append((y + dy, x + dx))\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def display_masks(mask1, mask2):\n",
    "    mask1_d = np.zeros((*mask1.shape, 3), dtype=np.uint8)\n",
    "    mask2_d = np.zeros((*mask2.shape, 3), dtype=np.uint8)\n",
    "\n",
    "    mask1_d[mask1 == 255] = [255, 0, 0]\n",
    "    mask2_d[mask2 == 255] = [0, 255, 0]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mask1_d, alpha=0.5)\n",
    "    plt.imshow(mask2_d, alpha=0.3)\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(original_path, annotated_path):\n",
    "    os.makedirs(original_path, exist_ok=True)\n",
    "    os.makedirs(annotated_path, exist_ok=True)\n",
    "\n",
    "    mask_files = glob.glob(str(annotated_path) + \"*.png\")\n",
    "    image_files = glob.glob(str(original_path) + \"*.jpg\")\n",
    "\n",
    "    PATCH_SIZE = 512\n",
    "\n",
    "    for mask_file in tqdm(mask_files):\n",
    "        mask_image = Image.open(mask_file).convert(\"L\")\n",
    "        mask = np.asarray(mask_image)\n",
    "        mask_fixed = np.zeros_like(mask)\n",
    "        # reject any values that are not 0 or 255\n",
    "        for iy, ix in np.ndindex(mask.shape):\n",
    "            if mask[iy, ix] > 127:\n",
    "                mask_fixed[iy, ix] = 255\n",
    "            else:\n",
    "                mask_fixed[iy, ix] = 0\n",
    "\n",
    "        assert np.all(np.logical_or(mask_fixed == 0, mask_fixed == 255))\n",
    "\n",
    "        mask_fixed = BFS(mask_fixed)\n",
    "        # display_masks(mask, mask_fixed)\n",
    "\n",
    "        mask_fixed = cv2.resize(\n",
    "            mask_fixed, (PATCH_SIZE, PATCH_SIZE), interpolation=cv2.INTER_NEAREST\n",
    "        )\n",
    "        mask_fixed = Image.fromarray(mask_fixed)\n",
    "        mask_fixed.save(mask_file)\n",
    "\n",
    "    for image_file in tqdm(image_files):\n",
    "        image = np.asarray(Image.open(image_file).convert(\"RGB\"))\n",
    "        image = cv2.resize(\n",
    "            image, (PATCH_SIZE, PATCH_SIZE), interpolation=cv2.INTER_CUBIC\n",
    "        )\n",
    "        image = Image.fromarray(image)\n",
    "        image.save(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup(\"./original/\", \"./annotated/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class TempDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.files = glob.glob(path + \"/*.jpg\")\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.asarray(Image.open(self.files[idx]))\n",
    "        image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "dataset = TempDataset(path=\"./original\")\n",
    "loader = DataLoader(dataset, batch_size=len(dataset))\n",
    "\n",
    "mean = 0\n",
    "std = 0\n",
    "\n",
    "for images in loader:\n",
    "    batch_samples = images.size(0)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "\n",
    "print(mean / len(dataset))\n",
    "print(std / len(dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
