{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.utils\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"original/\"\n",
    "mask_dir = \"annotated/\"\n",
    "\n",
    "img_paths = [file for file in Path(img_dir).iterdir() if not file.name.startswith(\".\")]\n",
    "mask_paths = [\n",
    "    file for file in Path(mask_dir).iterdir() if not file.name.startswith(\".\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"image_path\": img_paths, \"mask_paths\": mask_paths}, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CuffDataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        # df contains the paths to all files\n",
    "        self.df = df\n",
    "        # transforms is the set of data augmentation operations\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.df.iloc[idx, 0]), dtype=np.float32) / 255\n",
    "        mask = np.array(Image.open(self.df.iloc[idx, 1]), dtype=np.float32) / 255\n",
    "\n",
    "        augmented = self.transforms(image=image, mask=mask)\n",
    "        image = augmented[\"image\"]  # Dimension (3, 255, 255)\n",
    "        mask = augmented[\"mask\"]  # Dimension (255, 255)\n",
    "        image = normalize(\n",
    "            image, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), inplace=True\n",
    "        )\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 256\n",
    "\n",
    "transforms = A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(width=PATCH_SIZE, height=PATCH_SIZE, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Transpose(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df into train and test data\n",
    "train_df, val_df = train_test_split(df, test_size=0.2)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CuffDataset(train_df, transforms=transforms)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=28, shuffle=False)\n",
    "\n",
    "val_dataset = CuffDataset(val_df, transforms=transforms)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = np.float32(img)\n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    plt.imshow(npimg, vmin=0, vmax=1)\n",
    "\n",
    "\n",
    "dataiter = iter(train_dataloader)\n",
    "images, masks = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "plt.figure()\n",
    "imshow(torchvision.utils.make_grid(masks))\n",
    "plt.figure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
